{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Network with Credit Card Fraud\n",
    "\n",
    "Credit Card Transactions Fraud Detection Example:\n",
    "\n",
    "The notebook demonstrates how to develop a fraud detection application with the BigDL deep learning library on Apache Spark. We'll try to introduce some techniques that can be used for training a fraud detection model, but some advanced skills is not applicable since the dataset is highly simplified.\n",
    "\n",
    "Dataset: Credit Card Fraud Detection https://www.kaggle.com/dalpozz/creditcardfraud\n",
    "\n",
    "This dataset presents transactions that occurred in two days, where we got 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. \n",
    "\n",
    "Unfortunately, due to confidentiality issues, we cannot find the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Contact: yuhao.yang@intel.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.dataset.base import *\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from bigdl.models.ml_pipeline.dl_classifier import *\n",
    "from utils import *\n",
    "\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import  Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 1000\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28\n",
    "n_classes = 2\n",
    "n_hidden_1 = 100 # 1st layer number of features\n",
    "n_hidden_2 = 100 # 2nd layer number of features\n",
    "\n",
    "LABELS = [\"Normal\", \"Fraud\"]\n",
    "\n",
    "cols = [\"V\" + str(x) for x in list(range(1,28))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_training = spark.read.csv(\"../data/creditcardfraud/creditcard-small.csv.gz\", header=True, inferSchema=\"true\", mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/creditcardfraud/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+-------------------+------------------+-------------------+\n",
      "|summary|             Time|                  V1|                 V2|            Amount|              Class|\n",
      "+-------+-----------------+--------------------+-------------------+------------------+-------------------+\n",
      "|  count|             9061|                9061|               9061|              9061|               9061|\n",
      "|   mean|93758.12713828495|-0.25424247762411734|0.17199660579747025| 89.94237611742561| 1.0542986425339367|\n",
      "| stddev|47581.01643785861|  2.7091274040820754|   2.09513286985668|252.94831781126243|0.22661855121864016|\n",
      "|    min|               35|   -33.0171744306281|  -39.8183101230426|               0.0|                  1|\n",
      "|    max|           172741|    2.40466311881484|   22.0577289904909|          11898.09|                  2|\n",
      "+-------+-----------------+--------------------+-------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_training.select('Time', 'V1', 'V2', 'Amount', 'Class').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_training = cc_training.select([col(c).cast(\"double\") for c in cc_training.columns])\n",
    "cc_training = cc_training.withColumn(\"label\", cc_training[\"Class\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Balance\n",
    "\n",
    "Let us see the dataset balance. We suspect a highly unbalanced dataset -- let us visualize. that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEY38f9sUYHQ+uHeuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d45851f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count_classes = pd.value_counts(df['Class'], sort = True)\n",
    "count_classes = pd.value_counts(cc_training.select('Class').toPandas()['Class'], sort = True)\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the time to split the data.\n",
    "splitTime = cc_training.stat.approxQuantile(\"Time\", [0.7], 0.001)[0]\n",
    "\n",
    "trainingData =cc_training.filter(\"Time < \" + str(splitTime))\n",
    "validData = cc_training.filter(\"Time >= \" + str(splitTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature analysis:\n",
    "Normally it would improve the model if we could derive more features from the raw transaction records. E.g.\n",
    "days to last transaction,\n",
    "distance with last transaction,\n",
    "amount percentage over the last 1 month / 3months\n",
    "...\n",
    "\n",
    "Yet with the public dataset, we can hardly derive any extention features from the PCA result. So here we only introduce several general practices:\n",
    "\n",
    "Usually there's a lot of categorical data in the raw dataset, E.g. post code, card type, merchandise id, seller id, etc. \n",
    "\n",
    "1). For categorical feature with limited candidate values, like card type, channel id, just use OneHotEncoder. \n",
    "\n",
    "2). For categorical feature with many candidate values, like merchandise id, post code or even phone number, suggest to use Weight of Evidence. \n",
    "\n",
    "3). You can also use FeatureHasher from Spark MLlib which will be release with Spark 2.3.\n",
    "For this dataset, essentially it's a classification problem with highly unbalanced data set.\n",
    "\n",
    "## Approach\n",
    "\n",
    "We will build a feature transform pipeline with Apache Spark and some of our transformers.\n",
    "We will run some inital statistical analysis and split the dataset for training and validation.\n",
    "We will build the model with BigDL.\n",
    "We will compare different strategy to handle the unbalance.\n",
    "Details of each step is as follows:\n",
    "\n",
    "### step 1. Build an inital pipeline for feature transform.\n",
    "For each training records, we intend to aggregate all the features into one Spark Vector, which will then be sent to BigDL model for the training. First we'd like to introduce one handy transformer that we developed to help user build custom Transformers for Spark ML Pipeline.\n",
    "```\n",
    "class FuncTransformer (\n",
    "  override val uid: String,\n",
    "  val func: UserDefinedFunction\n",
    ") extends Transformer with HasInputCol with HasOutputCol with DefaultParamsWritable {\n",
    "```\n",
    "FuncTransformer takes an udf as the constructor parameter and use the udf to perform the actual transform. The transformer can be saved/loaded as other transformer and can be integrated into a pipeline normally. It can be used widely in many use cases like conditional conversion(if...else...), , type conversion, to/from Array, to/from Vector and many string ops. Some examples:\n",
    "```\n",
    "val labelConverter = new FuncTransformer(udf { i: Double => if (i >= 1) 1 else 0 })\n",
    "```\n",
    "\n",
    "```\n",
    "val shifter = new FuncTransformer(udf { i: Double => i + 1 })\n",
    "```\n",
    "\n",
    "```\n",
    "val toVector = new FuncTransformer(udf { i: Double => Vectors.dense(i) })\n",
    "```\n",
    "\n",
    "We will use VectorAssembler to compose the all the Vx columns and append the Amount column. Then use StandardScaler to normlize the training records. Since in BigDL, the criterion generally only accepts 1, 2, 3... as the Label, so we will replace all the 0 with 2 in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =  VectorAssembler(inputCols=cols, outputCol=\"assembled\")\n",
    "scaler = StandardScaler(inputCol=\"assembled\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages = [assembler, scaler])\n",
    "pipelineTraining = pipeline.fit(trainingData)\n",
    "data_training = pipelineTraining.transform(trainingData)\n",
    "pipelineTest = pipeline.fit(validData)\n",
    "data_test = pipelineTraining.transform(validData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2. split the dataset into training and validation dataset.\n",
    "\n",
    "Unlike some other training dataset, where the data does not have a time of occurance. For this case, we can know the sequence of the transactions from the Time column. Thus randomly splitting the data into training and validation does not make much sense, since in real world applications, we can only use the history transactions for training and use the latest transactions for validation. Thus we'll split the dataset according the time of occurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3. Build the model with BigDL\n",
    "From the research community and industry feedback, a simple neural network turns out be the perfect candidate for the fraud detection training. We will quickly build a multiple layer Perceptron with linear layers.\n",
    "```\n",
    "    val bigDLModel = Sequential()\n",
    "      .add(Linear(29, 10))\n",
    "      .add(Linear(10, 2))\n",
    "      .add(LogSoftMax())\n",
    "    val criterion = ClassNLLCriterion()\n",
    "```\n",
    "\n",
    "BigDL provides DLEstimator and DLClassifier for users with Apache Spark MLlib experience, which provides high level API for training a BigDL Model with the Apache Spark Estimator/Transfomer pattern, thus users can conveniently fit BigDL into a ML pipeline. The fitted model DLModel and DLClassiferModel contains the trained BigDL model and extends the Spark ML Model class. Alternatively users may also construct a DLModel with a pre-trained BigDL model to use it in Spark ML Pipeline for prediction.\n",
    "\n",
    "DLClassifier is a specialized DLEstimator that simplifies the data format for classification tasks. It only supports label column of DoubleType, and the fitted DLClassifierModel will have the prediction column of DoubleType.\n",
    "\n",
    "For this case we'll just use DLClassifier for the training. Note that users can set differet optimization mothod, batch size and epoch number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createSequential\n",
      "creating: createLinear\n",
      "creating: createLinear\n",
      "creating: createLogSoftMax\n",
      "creating: createClassNLLCriterion\n",
      "creating: createDLClassifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bigDLModel = Sequential().add(Linear(n_input, n_hidden_1)).add(Linear(n_hidden_1, n_classes)).add(LogSoftMax())\n",
    "classnll_criterion = ClassNLLCriterion()\n",
    "dlClassifier = DLClassifier(model=bigDLModel, criterion=classnll_criterion, feature_size=[n_input])\n",
    "dlClassifier.setLabelCol(\"label\").setMaxEpoch(training_epochs).setBatchSize(batch_size)\n",
    "model = dlClassifier.fit(data_training)\n",
    "print(\"\\ninitial model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, SQLContext\n",
    "predictionDF = DataFrame(model.transform(cc_data_test), SQLContext(sc))\n",
    "predictionDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we have finished the training of our first model (which is certainly not the best, keep reading!).\n",
    "\n",
    "We'll need to think about how do evaluate the trained model:\n",
    "\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification. Since even if the model predicts all the records as normal transactions, it will still get an accuracy above 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDF.cache() \n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "auPRC = evaluator.evaluate(predictionDF)\n",
    "print(\"\\nArea under precision-recall curve: = \" + auPRC)\n",
    "    \n",
    "recall = MulticlassClassificationEvaluator(metricName=\"weightedRecall\").evaluate(predictionDF)\n",
    "print(\"\\nrecall = \" + recall)\n",
    "\n",
    "precision = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\").evaluate(predictionDF)\n",
    "print(\"\\nPrecision = \" + precision)  \n",
    "predictionDF.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(predictionDF.select('prediction').collect())\n",
    "y_true = np.array(predictionDF.select('label').collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, we have finished the training and evaluation with a simple BigDL model. We can see that even though the recall and precision are high, the area under precision-recall curve is not optimistic. That's because we haven't really apply any technique to handle the imbalanced training data.\n",
    "\n",
    "Next we'll try to optimize the training process.\n",
    "\n",
    "### step 4. handle the data imbalance\n",
    "There are several ways to approach this classification problem taking into consideration this unbalance.\n",
    "\n",
    "Collect more data? Nice strategy but not applicable in this case.\n",
    "\n",
    "Resampling the dataset Essentially this is a method that will process the data to have an approximate 50-50 ratio. One way to achieve this is by OVER-sampling, which is adding copies of the under-represented class (better when there're little data) Another is UNDER-sampling, which deletes instances from the over-represented class (better when there are lots of data)\n",
    "Apart from under and over sampling, there is a very popular approach called SMOTE (Synthetic Minority Over-Sampling Technique), which is a combination of oversampling and undersampling, but the oversampling approach is not by replicating minority class but constructing new minority class data instance via an algorithm.\n",
    "\n",
    "We'll start with Resampling.\n",
    "\n",
    "Since there're 492 frauds out of 284,807 transactions, to build a reasonable training dataset, we'll use UNDER-sampling for normal transactions and use OVER-sampling for fraud transactions. By using the sampling rate as fraud -> 10, normal -> 0.05, we can get a training dataset of (5K fraud + 14K normal) transactions. We can use the training data to fit a model.\n",
    "\n",
    "Yet we'll soon find that since there're only 5% of all the normal transactions are included in the training data, the model can only cover 5% of all the normal transactions, which is obviousely not optimistic. So how can we get a better converage for the normal transactions without breaking the ideal ratio in the training dataset?\n",
    "\n",
    "An immediate improvement would be to train multiple models. For each model, we will run the resampling from the original dataset and get a new training data set. After training, we can select best voting strategy for all the models to make the prediction.\n",
    "\n",
    "We'll use Ensembling of neural networks. That's where a Bagging classifier becomes handy. Bagging is an Estimator we developed for ensembling of multiple other Estimator.\n",
    "\n",
    "```\n",
    "package org.apache.spark.ml.ensemble\n",
    "\n",
    "class Bagging[M <: Model[M]](override val uid: String)\n",
    "  extends Estimator[BaggingModel[M]]\n",
    "  with BaggingParams[M] {\n",
    "For usage, user need to set the specific Estimator to use and the number of models to be trained:\n",
    "    val estimator = new Bagging()\n",
    "      .setPredictor(dlClassifier)\n",
    "      .setLabelCol(\"Class\")\n",
    "      .setIsClassifier(true)\n",
    "      .setNumModels(10)\n",
    "```\n",
    "\n",
    "Internally, Bagging will train $(numModels) models. Each model is trained with the resampled data from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frpm pyspark.ml.ensemble import Bagging\n",
    "estimator = Bagging().setPredictor(dlClassifier).setLabelCol(\"Class\").setIsClassifier(true).setNumModels(20)\n",
    "\n",
    "val baggingModel = estimator.fit(cc_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
