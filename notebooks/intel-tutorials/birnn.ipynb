{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Classfication using Bidirectional Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going to use the MNIST dataset to train a multi-layer feed foward neural network. MNIST is a simple computer vision dataset of handwritten digits. It has 60,000 training examles and 10,000 test examples. \"It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\" For more details, please checkout the website [MNIST](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas\n",
    "import datetime as dt\n",
    "\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.dataset import mnist\n",
    "from utils import get_mnist\n",
    "\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the \"mnist_path\" accordingly. If the \"mnist_path\" directory does not consist of the mnist data, mnist.read_data_sets method will download the dataset directly to the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and store MNIST into RDD of Sample, please edit the \"mnist_path\" accordingly.\n",
    "mnist_path = \"datasets/mnist\"\n",
    "(train_data, test_data) = get_mnist(sc, mnist_path)\n",
    "\n",
    "train_data = train_data.map(lambda s: Sample.from_ndarray(np.resize(s.features, (28, 28)), s.label))\n",
    "test_data = test_data.map(lambda s: Sample.from_ndarray(np.resize(s.features, (28, 28)), s.label))\n",
    "print(train_data.count())\n",
    "print(test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bidirectional Recurrent Neural Network Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional RNNs are based on the idea that the output at time t may not only depend on the previous elements in the sequence, but also future elements. They combine an RNN that moves foward through time beginning from the end of the sequence with another RNN that moves backward through time from the end of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 64\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size, hidden_size, output_size):\n",
    "    model = Sequential()\n",
    "    recurrent = BiRecurrent(JoinTable(3, 3))\n",
    "    recurrent.add(LSTM(input_size, hidden_size))\n",
    "    model.add(InferReshape([-1, input_size], True))\n",
    "    model.add(recurrent)\n",
    "    model.add(Select(2, -1))\n",
    "    model.add(Linear(2*hidden_size, output_size))\n",
    "    return model\n",
    "rnn_model = build_model(n_input, n_hidden, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Optimizer\n",
    "\n",
    "criterion = CrossEntropyCriterion()\n",
    "optimizer = Optimizer(\n",
    "    model=rnn_model,\n",
    "    training_rdd=train_data,\n",
    "    criterion=criterion,\n",
    "    optim_method=Adam(),\n",
    "    end_trigger=MaxEpoch(5),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Set the validation logic\n",
    "optimizer.set_validation(\n",
    "    batch_size=batch_size,\n",
    "    val_rdd=test_data,\n",
    "    trigger=EveryEpoch(),\n",
    "    val_method=[Top1Accuracy()]\n",
    ")\n",
    "\n",
    "app_name='rnn-'+dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_summary = TrainSummary(log_dir='/tmp/bigdl_summaries',\n",
    "                                     app_name=app_name)\n",
    "train_summary.set_summary_trigger(\"Parameters\", SeveralIteration(50))\n",
    "val_summary = ValidationSummary(log_dir='/tmp/bigdl_summaries',\n",
    "                                        app_name=app_name)\n",
    "optimizer.set_train_summary(train_summary)\n",
    "optimizer.set_val_summary(val_summary)\n",
    "print(\"saving logs to \",app_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Boot training process\n",
    "trained_model = optimizer.optimize()\n",
    "print(\"Optimization Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predict_label(l):\n",
    "    return np.array(l).argmax()\n",
    "def map_groundtruth_label(l):\n",
    "    return l[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = trained_model.predict(test_data)\n",
    "imshow(np.column_stack([np.array(s.features).reshape(28,28) for s in test_data.take(8)]),cmap='gray'); axis('off')\n",
    "print('Ground Truth labels:')\n",
    "print(', '.join(str(map_groundtruth_label(s.label)) for s in test_data.take(8)))\n",
    "print('Predicted labels:')\n",
    "print(', '.join(str(map_predict_label(s)) for s in predictions.take(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Draw the performance curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.array(train_summary.read_scalar(\"Loss\"))\n",
    "top1 = np.array(val_summary.read_scalar(\"Top1Accuracy\"))\n",
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(loss[:,0],loss[:,1],label='loss')\n",
    "plt.xlim(0,loss.shape[0]+10)\n",
    "plt.grid(True)\n",
    "plt.title(\"loss\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(top1[:,0],top1[:,1],label='top1')\n",
    "plt.xlim(0,loss.shape[0]+10)\n",
    "plt.title(\"top1 accuracy\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
